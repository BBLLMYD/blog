<br>

很多业务场景下也都需要用各种"锁"来控制并发场景对资源的各类操作。
各种同步手段可以说都是为了解决并发场景下对数据的操作而出现的，
而对数据的并发场景，多数都在多读多写、多读少写、少读多写、少读少写这几个常见范围内，
不同的并发场景下到达性能瓶颈节点的因素条件也不尽相同，
导致对于"锁"手段的方案选用和优化成了整体性能指标中很重要的一环。

维基百科中关于"线程/进程同步"的部分描述：

> 线程同步被定义为一种确保两个或多个并发进程或线程不会同时执行某些特定程序段（称为关键段）的机制。通过使用同步技术来控制进程对关键部分的访问。当一个线程开始执行关键部分（程序的序列化段）时，另一个线程应等待，直到第一个线程完成。如果未应用适当的同步技术，则可能导致争用情况，其中变量的值可能不可预测，并根据进程或线程的上下文切换的时间而变化。 

当要处理的资源操作控制在不同位置，往往也依赖着不同中间件的处理手段。
**由于不同中间件环境的上下文等条件不同，实现的方式上总会有所差别，但是控制逻辑的抽象往往都是相通或类似的。**

这一篇大概从下面几个方面出发，结合场景特点来展开讨论关于"锁"的各种实现和选型的方向。

- [1. 进程内的锁](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E9%94%81%E2%80%9D.md#1%E7%A8%8B%E5%BA%8F%E8%BF%9B%E7%A8%8B%E5%86%85%E7%9A%84%E9%94%81)
- [2. 分布式锁](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E9%94%81%E2%80%9D.md#2%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81)
- [3. 数据库锁](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E9%94%81%E2%80%9D.md#3%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81)
- [4. 其他](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E9%94%81%E2%80%9D.md#4%E5%85%B6%E4%BB%96)
- [5. 总结](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E9%94%81%E2%80%9D.md#5%E6%80%BB%E7%BB%93)

- - -

<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/07/0701.png?raw=true" width="778"></div>
<br>

### 1.程序进程内的锁

由于Java中的线程单位是直接映射到操作系统线程的，所以Java中线程的状态切换也同步会天然带着操作系统线程切换本身的开销，
如果在类似go语言中的协程机制，就可以相对更加细化锁和线程概念的粒度，可以一定程度的避免开销。

#### 内置锁
内置锁synchronized从最初简单的完全互斥的实现方式，随着JDK的版本迭代内置的锁逻辑也在不断的优化，包括但不限于下面的几个方面：

* 锁消除：消除的判定基于逃逸分析的技术支持，明确了其实是线程私有的场景同步操作自然就可以取消。
* 锁粗化：当同步的模块很小又连续对其加锁且没有竞争的时候，虚拟机会把锁的粒度粗化到整体操作外部变成同一把，比如连续的append()时。
* 偏向锁：这也是一个可配置参数的锁，可用-XX:+/-UseBiasedLocking来显示开启/禁止，
* 适应性锁：为了避免阻塞引入的自旋操作，避免自旋过多而浪费CPU引入了适应性自旋，次数阈值可以使用-XX:PreBlockSpin来显示指定。
以上的几个操作的实现和状态的更新，都是基于虚拟机对象头Mark Word的存储和标识位内容规范来实现的。



|     存储内容     |     标识位    |     状态     |
|      :-:        |     :-:      |      :-:      |
|  对象的hash码、分代年龄  |  01  |  未锁定  |
|  指向锁记录的指针  |  00  |  轻量级锁定  |
|  指向重量级锁的指针  |  10  |  膨胀（重量级锁）  |
|  空，不需要记录信息（已被GC标记）  |  11  |  GC标记  |
|  偏向线程ID、偏向时间戳、对象分代年龄  |  01  |  可偏向  |



#### 显式锁

显示锁是由Java语言层封装的锁工具，提供了更灵活的特性配置，使用上虽然直观易于理解，
但如果使用不严谨也很容易发生锁泄漏的现象，并且在线程转储的时候有可能不包含锁的信息。
从我个人来讲，内置锁能够满足的情况下一般不会使用显示锁，大多同步场景确实内置锁也都是可以满足的，而比如一些需要公平锁实现的场景，使用显示锁会更方便。
并且在性能上，内置锁也在由虚拟机不断的进行优化中。我认为显示锁更大的价值在其设计思想上，
基于强大的AQS的基础队列，实现了一系列同步工具，ReentrantLock只是AQS的应用之一。


### 2.分布式锁

分布式锁其实本质也是进程内的锁，只不过锁资源不再局限于上面的应用程序的进程内而是转移到了某个中间件的进程内，而通常中间件又是需要做高可用，
这又引入了分布式锁资源的一致性等问题。

一般用于实现分布式锁的中间件有mysql、redis、zk等

* mysql：mysql可以通过设计一张业务隔离的与锁相关的一张表，通过锁的资源粒度等信息确定字段范围，比较直观易于理解，但是受制于mysql的表操作性能会相对内存操作比较低。
* zk：zk本质上也是一个数据存储的中间件，只不过其特性是以分布式服务的协调为主，适合存量级较少的元数据。性能相比redis也不占优势，对高并发不是很友好，好处是支持读写锁，ZK获取锁会按照加锁的顺序，所以是天然的公平锁。
* redis：redis应该是分布式锁覆盖最广的方案了，其中[Redisson](https://github.com/redisson/redisson/wiki)是一个从性能和功能上都比较完备的客户端工具，
相比Jedis有更加丰富的抽象，并且提供了较丰富的功能如WatchDog机制和基于Java并发包下扩展的读写锁、信号量等等。
Redisson实现了Java并发包中的Lock接口同时也实现了可重入、公平锁等特性，
Redisson的内部很多操作都是封装了LUA脚本来满足原子性。

分布式锁的安全问题

无论是什么中间件，使用分布式锁要注意的问题很多，有常见的比如如何避免死锁、如何保证解锁的线程和加锁的线程是同一个Client等。
还有一些在极端情况下的问题如GC的STW（当FullGC的STW时间超过了锁的超时时间）、时钟发生跳跃（时钟跳跃会导致锁的预期释放时间不符）、长时间的网络I/O等（和前面的STW可以类比）。

在使用分布式锁的时候这些问题未必都要列在需要考虑的范围内，
而随着分布式锁使用的越来越重，在全局下可能会出现的问题list和以及对当下的业务可能会产生的影响就不能够忽略了。
墨菲定律说：如果你担心某种情况发生，那么它就更有可能发生。
对于重要的业务场景来说，在可见范围内找到所有有可能的异常都列出来使其尽量不发生，或者无法绝对避免发生时发生的后果能够可控，一定是十分重要的。

### 3.数据库锁

上面提到了数据库锁也可算是分布锁的一种方案，
数据库的锁**本质也是对状态位的读、写、判断**，只不过大部分的锁行为都已经被数据库封装好了，
数据库通常会根据sql语句类型和事务隔离级别加不同的锁类型和粒度，我们在上层应用往往需要指定适合的隔离级别即可，
当然也可以hint手工强行来指定，比如：select * from table(tablockx) (强行加排他锁）。

通常在数据库层面我们不会显示的指定锁，这样对业务的入侵太严重，
而会从应用的业务数据层面上加排他锁或者上面脑图中所示的通过版本号等手段的乐观锁实现控制并发。

另外需要注意的包括：加锁的粒度，尽量避免表锁；监控行锁冲突(事务锁)，
为使用者提供行锁冲突的信息(对应的SQL语句、对应的事务ID，通过binlog来查询事务对应的SQL语句)，
通过优化应用逻辑降低行锁冲突；降低行锁冲突的超时时间（行锁超时参数：innodb_lock_wait_timeout，表锁超时参数：lock_wait_timeout）等等。



### 4.其他

#### 线程的活性故障
处于非RUNNABLE状态的线程有可能会是一个非正常工作的线程，如死锁、活锁、锁死、饥饿这几个状态下，
，上面几个状态通常是由于编码的错误或者缺陷导致，在多线程环境中的开发要尽量避免这种可能性，出现可能会导致很严重的生产故障。

#### 线程上下文切换的开销
发生上下文切换的原因和大致内容在[关于I/O](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9CIO%E2%80%9D.md#ps%E5%85%B3%E4%BA%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E7%9A%84%E4%B8%80%E7%82%B9%E8%AE%A8%E8%AE%BA)的一篇文章中已经提到过，
这里主要说一下上下文切换引发的具体开销。
* 时间上的开销：1.操作系统保存和恢复上下文所需处理器的时间；2.处理器高速缓存重新加载的时间消耗，
* 空间上的低效：其实空间说开销有点言重，不如说空间上的浪费，处理器高速缓存重新加载可能会导致原有的L1、L2、L3几级的缓存内容降级，而不必要的来回切换会导致[局部性](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86%E2%80%9D.md)空间效率比较低。

#### 一些并发容器的实现思路
* ConcurrentHashMap：将锁的资源分段，资源的粒度变细，自然也就支持更大的并发写操作，劣势是当需要拿到全局属性比如size的时候，需要同时获取到各个段的锁。
* CopyOnWriteArrayList：不变模式，将读和写基于的操作对象分离，也是以空间换时间的思想，这样只要需控制写-写的并发场景，对读多写少比较友好。
* ConcurrentLinkedQueue：CAS机制实现对Node的更新操作，由于考虑到各种操作可能的数据不一致，实现上会相对复杂，并且CAS也不适用于写数据过多的场景。
...

总之并发容器的本质，是在容器内部对数据结构的一系列操作进行数据正确的保障，
而对容器的使用者屏蔽掉了细节。但是由于各种实现同步的手段区别，
同样满足并发的容器也是适用于不同的读写场景的。
所以只有当了解了同步策略后，我们才能在需要同步容器的时候更自由的结合业务来选型。

### 5.总结

我个人认为当使用锁的时候，无论是进程内的锁还是分布式锁或者数据库锁，基本就是涉及到了并发场景的数据安全，
而安全性的基础是需要第一优先级的保证。我觉得这和[设计模式](https://github.com/BBLLMYD/blog/blob/master/blogs/%E6%8A%BD%E8%B1%A1%E4%B9%8B%E4%BA%8E%E2%80%9C%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%9D.md)
的应用也是一个道理，
锁的选型一开始不应该太想当然，首先保证程序安全的前提下，再结合业务场景的特性一步一步的升级锁策略寻找最适合的才是最好方法。
而在后面一步一步的锁优化过程中，需要有足够扎实的并发相关的基础知识和理论来支撑，这样不管锁的资源在哪里，抽象出的理论往往都是相同的，在各个场景下实现和选型上自然也就熟能生巧了。


