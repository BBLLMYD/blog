TCP/IP协议的用途不需多说，是绝大多数应用采用的基础协议，
因为TCP/IP的特性是可靠传输。协议的本质毕竟是规范，
真正完成协议所规范内容的还是需要硬件和操作系统支持。

并且网络环境有太多的不可控，丢包、乱序、重传、拥塞现象常见，
既然是承诺可靠的协议，针对以上现象就都需要作出相应的算法策略来保障可靠性。

> TCP/IP传输协议，即传输控制/网络协议，也叫作网络通讯协议。它是在网络的使用中的最基本的通信协议。TCP/IP传输协议对互联网中各部分进行通信的标准和方法进行了规定。并且，TCP/IP传输协议是保证网络数据信息及时、完整传输的两个重要的协议。TCP/IP传输协议是严格来说是一个四层的体系结构，应用层、传输层、网络层和数据链路层都包含其中。

这篇讨论从下面的几个方面来展开，从协议的机制到OS对协议的实现和特性，以及在基于TCP的应用层关于TCP连接状态等的一些状况。

- [1.从TCP头部包含信息来看TCP协议一些机制](https://github.com/BBLLMYD/blog/blob/master/blogs/%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8ETCP-IP%E7%9A%84%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8.md#1%E4%BB%8Etcp%E5%A4%B4%E9%83%A8%E5%8C%85%E5%90%AB%E4%BF%A1%E6%81%AF%E6%9D%A5%E7%9C%8Btcp%E5%8D%8F%E8%AE%AE%E4%B8%80%E4%BA%9B%E6%9C%BA%E5%88%B6)
- [2.Linux对TCP协议是如何抽象及实现的](https://github.com/BBLLMYD/blog/blob/master/blogs/%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8ETCP-IP%E7%9A%84%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8.md#2linux%E5%AF%B9tcp%E5%8D%8F%E8%AE%AE%E6%98%AF%E5%A6%82%E4%BD%95%E6%8A%BD%E8%B1%A1%E5%8F%8A%E5%AE%9E%E7%8E%B0%E7%9A%84)
- [3.TCP建立 & 断开连接（握手 & 挥手）以及状态位](https://github.com/BBLLMYD/blog/blob/master/blogs/%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8ETCP-IP%E7%9A%84%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8.md#3tcp%E5%BB%BA%E7%AB%8B%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5%E6%8F%A1%E6%89%8B%E6%8C%A5%E6%89%8B%E4%BB%A5%E5%8F%8A%E7%8A%B6%E6%80%81%E4%BD%8D)
- [4.长链接下出现粘包/拆包的原因和应对方案](https://github.com/BBLLMYD/blog/blob/master/blogs/%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8ETCP-IP%E7%9A%84%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8.md#4%E9%95%BF%E9%93%BE%E6%8E%A5%E4%B8%8B%E5%87%BA%E7%8E%B0%E7%B2%98%E5%8C%85%E6%8B%86%E5%8C%85%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%92%8C%E5%BA%94%E5%AF%B9%E6%96%B9%E6%A1%88)
- [5.基于TCP的应用要注意的几点以及一些可能的优化](https://github.com/BBLLMYD/blog/blob/master/blogs/%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8ETCP-IP%E7%9A%84%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8.md#5%E5%9F%BA%E4%BA%8Etcp%E7%9A%84%E5%BA%94%E7%94%A8%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%87%A0%E7%82%B9%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%8F%AF%E8%83%BD%E7%9A%84%E4%BC%98%E5%8C%96)

- - -

### 1.从TCP头部包含信息来看TCP协议一些机制

我们知道应用数据到发送到传输层的时候，会被增加一部分TCP头信息，为什么是这些数据，
上面提到了TCP需要在恶劣不可靠的环境下保证数据的可靠传输，
那么这部分头部信息包含的内容是如何被协议利用的呢。

<br>                                     
<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/09/0902.png?raw=true" width="765"></div>
<div align=center>TCP数据包</div>
<br>

上图中数据上面的部分都是TCP的头部信息。

- 从上往下看，先是源端口号目标端口号，由于传输层是不关注ip信息的，ip信息在下面的ip层添加，
后面再添加了一层ip信息之后**源ip+源端口+目的ip+目的端口就可以视为一个"TCP元组"**，可以确定唯一的一条TCP连接了。

- 序列号和确认序号就是发送过程中的seq和ack的值，**需要和FLAG的有效标志位配合才能够表示出准确的含义**，
在确认成功发送的同时序号的值也保证着包的顺序逻辑，避免包的乱序（保证ACK的是指定的seq）。



- 头部长度的字段是用来数据部分开始的位置的，因为头部可能也存在一些扩展字段信息，所以按照固定长度来计算会很大程度上降低灵活性。

- 上面提到的序列号和确认序号需要和FLAG配合，这里的FLAG其实就是六个状态（6个bit），
**当值为1的时候表示有效状态**，常规下SYN表示建立连接的同步信号；ACK用于对收到的数据进行确认；FIN通常用于发起断开连接；PSH表示有数据传输；RST表示连接重置；URG是紧急位为1的时候表示紧急指针有效；
其中SYN、ACK、FIN的意义是重点，因为在TCP的连接状态下，
他们的标志往往决定了Client端和Server端的状态，
这些状态需要**占用着系统的文件句柄资源，在大量连接下这些也是影响着系统吞吐量和性能**，以及应用传输数据期间是否是健康的状态重点参考的部分。

- 窗口尺寸是为了**动态的适应和平衡发送和接收方的处理能力**，做出合理的流量控制，避免发的太快造成拥堵，发的太慢造成饥饿。

<br>

- - -

### 2.Linux对TCP协议是如何抽象及实现的

无论是TCP还是UDP都是基于socket系统调用实现的。
Socket属于操作系统的概念，而非网络协议分层的概念。
操作系统选择对于网络协议的实现在二到四层的处理代码在内核里面、七层的处理代码让应用自己去做，**两者需要跨内核态和用户态通信**，
此时需要一个系统调用完成这个衔接，这就是Socket。

在Linux下一切都抽象成了文件，所以网络调用也是先从网络文件描述符开始，
对于给上层用户提供的函数接口常常使用的有如下这些。

<br>
<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/09/0903.png?raw=true" width="765"></div>
<div align=center>函数接口</div>
<br>

- socket() ：得到文件描述符
- bind() ：给描述符绑定IP和端口
- listen() ：初始化socket的一些变量，创建半连接和全连接队列，TCP状态置为TCP_LISTEN
- connect() ：进行握手
- accept() ：从完成三次握手的队列中取出一个Socket
- write() ：写数据
- read() ：读数据

上面提到的函数功能只是个很粗略的一个方向，实际上每个函数源码中的参数状态类型和数据结构以及函数计算内容要逻辑复杂的多。
想要建立TCP连接在流程上就离不开上面提到的函数调用，大致的时序流程如下图。

<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/09/0904.png?raw=true" width="449"></div>
<div align=center>Linux下TCP协议的函数调用</div>
<br>

- - -

### 3.TCP建立&断开连接（握手&挥手）以及状态位

首先明确建立连接是TCP层的动作，是在内核完成的，应用层是不需要参与这个过程的。
应用端更多是关注和判断系统和进程当前的连接状态等信息，明确当前资源的占用及用户进程的和内核交互通信的函数调用状况。

TCP是全双工的协议，任何一方都可以发起连接和断开的请求，通常我们称发起请求的一方为Client端，
但是断开连接的请求既可能是Client先发起也可能是Server端先发起的。

<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/09/0905.png?raw=true" width="765"></div>
<div align=center>建立/断开连接</div>

TCP的握手&挥手过程如上面的图，
其中每次交互传输的数据需要结合着TCP的数据包格式以及内容来看，
Seq代表序列号，需要找到值为Seq的值+1的ack作为正确响应的包，
而SYN/FIN标识位代表着请求的目的（是想要建立/断开连接），
ACK表示对状态的应答，需携带者有序值的ack来有效响应。
以上一些算法机制保证了即使在连接很多的情况下，也能够准确的通信。

除此之外我们更应该关注连接状态不同时期下的不同状态，如TIME_WAIT，CLOSE_WAIT等，
这些状态如果堆积过多，可能会影响系统的吞吐率，因为连接在这些状态下是要占用有限的句柄资源的，
通常堆积过多可能是操作系统参数配置不合理，也有可能是应用程序对连接的打开和关闭情况不规范导致。

Linux下当前系统里这些TCP状态分别的个数情况可以由下面的一个netstat命令查看。
````
netstat -n | grep  ^tcp | awk ‘{++S[$NF]} END {for(a in S) print a, S[a]}’
````
想要查看当前系统各进程对句柄资源的使用情况，可以用下面的losf命令。
````
lsof -n | awk '{print $2}'| sort|uniq -c|sort -nr | more
````
具体一点的优化建议放在下面来说，做优化的好的前提是能够真的理解为什么需要优化以及为啥可以优化，
这些都还是需要足够扎实基础知识做支撑的，
基础够扎实才能够在动态的环境下灵活的发现问题和优化，因为基础设施通常是不易变的。

- - -

### 4.长链接下出现粘包/拆包的原因和应对方案

上面说到对于丢包、乱序等现象TCP本身有算法来保障数据正确传输，
但是当我们基于TCP做上层应用时，还是有一些问题是需要在应用层做保障的，
比如长连接下的粘包拆包现象，TCP保证了数据在传输层的可靠性，
但是这些字节数据在TCP层面是无状态的，由于TCP的缓冲区机制可能导致应用层收到了半包或者粘包的数据。

因为TCP是面向字节流的协议，"流"本身可以看作是无状态、保证传输的时序顺序的不间断无逻辑边界的字节数据，也就是说TCP协议本身是不去立理解当下所传的数据的。
和UDP对比来看，TCP有缓冲区，而UDP面向报文段是没有缓冲区的。

TCP发送报文时，是将应用层数据写入TCP缓冲区中，然后由TCP协议来控制发送这里面的数据，
而发送的形式是按字节流的方式发送的，**跟应用层写下来的报文内容和长度没有任何关系**，所以说是流。
而UDP没有缓冲区，应用层写的报文数据会直接加包头交给网络层，由网络层负责分片，所以说是面向报文段的。

上面说到和应用层写下来的报文长度关系，也就是传输层此时一定程度上是不关注或者说不负责检查应用层写的数据内容和大小，
这些数据在传输层都是无差别的无状态的字节流。

那么在基于TCP传输的长链接场景，比如在应用程序写入的数据大于套接字缓冲区大小时，将会发生拆包现象；
应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上时将会发生粘包现象等。
发生上述现象的原因通常由于对TCP常常采用的一个算法Nagle导致，这种算法的本质是为了提高网络的利用率，
坏处也就是可能会带来上述问题，需要绝对避免上述问题的场景下通常也可以选择关闭这个算法，
为TCP连接设置TCP_NODELAY后，就可以禁用Nagle算法。

因为这数据粘连的影响是在应用层才体现的。也就需要在应用层面上来解决粘包拆包带来的问题。

- 从收发的角度：一个发送被多次接受（拆），多次发送被一次接受（粘）。
- 从传输的角度：一个发送占用多个传输包（拆），多个发送共用一个传输包（粘）。
       
<br>                                     
<div align=center><img src="https://github.com/BBLLMYD/blog/blob/master/images/09/0901.png?raw=true" width="867"></div>
<div align=center>粘/拆包及处理</div>
<br>


对于粘包拆包的原因如果理解了的话，其实不难想出在应用层应对这种现象的方法，往往也是一些通用的思想。
包括：发送方面和接受方约定固定的长度；约定指定分隔符；固定的位置用来存取存储报文长度等，他们优劣势在上图中也有说明。

- - -

### 5.基于TCP的应用要注意的几点以及一些可能的优化

在连接量比较大的情况下，通常要注意比如TIME_WAIT的连接的数量，
由于Linux对TIME_WAIT的默认时常设置是60秒 = 2MSL，
如果TIME_WAIT状态过多可能会导致句柄资源紧张降低应用的吞吐率，
而这么久的时常却通常是不必要的，此时需要调小TIME_WAIT等待的时间（通常调整为小于30秒）。

如果是CLOSE_WAIT状态过多，从挥手的流程状态图中可知是作为Server端没有及时ACK断开连接的请求，
此时也许是应用的负载过高线程数紧张，或者程序内忘记/漏掉关闭连接动作等原因导致，需要从应用的层面来排查和优化。




优化一方面是合理利用资源来提高应用程序的性能瓶颈，**前提是需要能够发现当下的瓶颈是否是资源利用的不合理导致**。

另一方面由于TCP为了满足可靠性对处理不确定的环境有着很多动作，而在基本很多封闭的内网安全可靠的环境下，
一些机制也许会显得有些冗余，此时也可以选择类似如TFO技术（tcp_fastopen参数）绕过三次握手等手段，
ps:Linux下有很多调整tcp协议相关的参数如tcp_timestamps,tcp_tw_reuse,tcp_max_tw_buckets等等，
如果想要针对业务系统更加合理的利用优化这些参数，需要对业务系统有足够程度的把控以及对协议本身有透彻的理解，
可能一点点小的但是足够准确的优化，在业务量庞大的时候或许也可以发挥出巨大的效益。


- - -

